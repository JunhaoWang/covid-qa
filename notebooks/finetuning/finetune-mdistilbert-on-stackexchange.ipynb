{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\r\n",
      "Version: 2.8.0\r\n",
      "Summary: State-of-the-art Natural Language Processing for TensorFlow 2.0 and PyTorch\r\n",
      "Home-page: https://github.com/huggingface/transformers\r\n",
      "Author: Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Sam Shleifer, Google AI Language Team Authors, Open AI team Authors, Facebook AI Authors, Carnegie Mellon University Authors\r\n",
      "Author-email: thomas@huggingface.co\r\n",
      "License: Apache\r\n",
      "Location: /opt/conda/lib/python3.6/site-packages\r\n",
      "Requires: sacremoses, sentencepiece, dataclasses, numpy, tokenizers, requests, tqdm, filelock, boto3, regex\r\n",
      "Required-by: \r\n"
     ]
    }
   ],
   "source": [
    "# Update to transformers 2.8.0\n",
    "!pip install -q transformers --upgrade\n",
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, average_precision_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers as trfm\n",
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512, enable_padding=False):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \n",
    "    ---\n",
    "    \n",
    "    Inputs:\n",
    "        tokenizer: the `fast_tokenizer` that we imported from the tokenizers library\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    if enable_padding:\n",
    "        tokenizer.enable_padding(max_length=maxlen)\n",
    "    \n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_qa_ids(q_ids, a_ids, tokenizer, maxlen=512):\n",
    "    \"\"\"\n",
    "    Given two arrays of IDs (questions and answers) created by\n",
    "    `fast_encode`, we combine and pad them.\n",
    "    Inputs:\n",
    "        tokenizer: The original tokenizer (not the fast_tokenizer)\n",
    "    \"\"\"\n",
    "    combined_ids = []\n",
    "\n",
    "    for i in tqdm(range(q_ids.shape[0])):\n",
    "        ids = []\n",
    "        ids.append(tokenizer.cls_token_id)\n",
    "        ids.extend(q_ids[i])\n",
    "        ids.append(tokenizer.sep_token_id)\n",
    "        ids.extend(a_ids[i])\n",
    "        ids.append(tokenizer.sep_token_id)\n",
    "        ids.extend([tokenizer.pad_token_id] * (maxlen - len(ids)))\n",
    "\n",
    "        combined_ids.append(ids)\n",
    "    \n",
    "    return np.array(combined_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_qa(questions, answers, tokenizer, chunk_size=256, maxlen=512):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    tokenizer.enable_padding(max_length=maxlen)\n",
    "    all_ids = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(questions), chunk_size)):\n",
    "        q_chunk = questions[i:i+chunk_size].tolist()\n",
    "        a_chunk = answers[i:i+chunk_size].tolist()\n",
    "        text_chunk = list(zip(q_chunk, a_chunk))\n",
    "        \n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "    \n",
    "    return np.array(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_text(text, tokenizer, chunk_size=256, maxlen=256):\n",
    "    \"\"\"\n",
    "    Ensure that the text does not have more than maxlen tokens\n",
    "    \"\"\"\n",
    "    tokenizer.enable_truncation(max_length=maxlen)\n",
    "    all_norm_str = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(text), chunk_size)):\n",
    "        chunk = text[i:i+chunk_size].tolist()\n",
    "        encs = tokenizer.encode_batch(chunk)\n",
    "        all_norm_str.extend([str(enc.normalized_str) for enc in encs])\n",
    "    \n",
    "    return all_norm_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=None):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    input_ids = L.Input(shape=(max_len, ), dtype=tf.int32)\n",
    "    \n",
    "    x = transformer(input_ids)[0]\n",
    "    x = x[:, 0, :]\n",
    "    x = L.Dense(1, activation='sigmoid', name='sigmoid')(x)\n",
    "    \n",
    "    # BUILD AND COMPILE MODEL\n",
    "    model = Model(inputs=input_ids, outputs=x)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy'], \n",
    "        optimizer=Adam(lr=1e-5)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, sigmoid_dir='transformer', transformer_dir='transformer'):\n",
    "    \"\"\"\n",
    "    Special function to load a keras model that uses a transformer layer\n",
    "    \"\"\"\n",
    "    os.makedirs(transformer_dir, exist_ok=True)\n",
    "    os.makedirs(sigmoid_dir, exist_ok=True)\n",
    "    \n",
    "    transformer = model.layers[1]\n",
    "    transformer.save_pretrained(transformer_dir)\n",
    "    \n",
    "    sigmoid_path = os.path.join(sigmoid_dir,'sigmoid.pickle')\n",
    "    sigmoid = model.get_layer('sigmoid').get_weights()\n",
    "    pickle.dump(sigmoid, open(sigmoid_path, 'wb'))\n",
    "\n",
    "    \n",
    "def load_model(sigmoid_dir='transformer', transformer_dir='transformer', \n",
    "               architecture=\"electra\", max_len=None):\n",
    "    \"\"\"\n",
    "    Special function to load a keras model that uses a transformer layer\n",
    "    \"\"\"\n",
    "    sigmoid_path = os.path.join(sigmoid_dir,'sigmoid.pickle')\n",
    "    \n",
    "    if architecture == 'electra':\n",
    "        transformer = trfm.TFElectraModel.from_pretrained(transformer_dir)\n",
    "    else:\n",
    "        transformer = trfm.TFAutoModel.from_pretrained(transformer_dir)\n",
    "    model = build_model(transformer, max_len=max_len)\n",
    "    \n",
    "    sigmoid = pickle.load(open(sigmoid_path, 'rb'))\n",
    "    model.get_layer('sigmoid').set_weights(sigmoid)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "MAX_LEN = 512\n",
    "MODEL = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text to matrices\n",
    "\n",
    "Caveat: Since a lot of the questions on stackexchange goes over 256, characters, we end up truncating a large part (if not all) of the answers. Thus, we need to \"pre\" truncate them by separately encode the questions and answers, and use a functions to combine them again.\n",
    "\n",
    "Note: Here we are not actually encoding it, instead we load the encoded q&a pairs from another notebook, in order to limit memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ids = np.load('/kaggle/input/encode-stackexchange-for-mdistilbert/correct_ids.npy')\n",
    "wrong_ids = np.load('/kaggle/input/encode-stackexchange-for-mdistilbert/wrong_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = np.concatenate([correct_ids, wrong_ids])\n",
    "\n",
    "labels = np.concatenate([\n",
    "    np.ones(correct_ids.shape[0]),\n",
    "    np.zeros(wrong_ids.shape[0])\n",
    "]).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(input_ids.shape[0]), \n",
    "    test_size=0.3, \n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "valid_idx, test_idx = train_test_split(\n",
    "    test_idx, \n",
    "    test_size=0.5, \n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = input_ids[train_idx]\n",
    "valid_ids = input_ids[valid_idx]\n",
    "test_ids = input_ids[test_idx]\n",
    "\n",
    "train_labels = labels[train_idx]\n",
    "valid_labels = labels[valid_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build datasets objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_ids, train_labels))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((valid_ids, valid_labels))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(test_ids)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b43e21f09134143aa92728a2a08d338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=618.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5852799a1c604f459930d63b370e817c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=910749124.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "tf_distil_bert_model (TFDist ((None, 512, 768),)       134734080 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "sigmoid (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 134,734,849\n",
      "Trainable params: 134,734,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 31.7 s, sys: 10 s, total: 41.8 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = trfm.TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 3209 steps, validate for 688 steps\n",
      "Epoch 1/8\n",
      "3209/3209 [==============================] - 790s 246ms/step - loss: 0.3599 - accuracy: 0.8426 - val_loss: 0.3025 - val_accuracy: 0.8781\n",
      "Epoch 2/8\n",
      "3209/3209 [==============================] - 730s 228ms/step - loss: 0.2631 - accuracy: 0.8941 - val_loss: 0.2935 - val_accuracy: 0.8854\n",
      "Epoch 4/8\n",
      "3209/3209 [==============================] - 732s 228ms/step - loss: 0.2408 - accuracy: 0.9035 - val_loss: 0.3057 - val_accuracy: 0.8846\n",
      "Epoch 5/8\n",
      "3209/3209 [==============================] - 732s 228ms/step - loss: 0.2189 - accuracy: 0.9128 - val_loss: 0.3206 - val_accuracy: 0.8828\n",
      "Epoch 6/8\n",
      "3209/3209 [==============================] - 732s 228ms/step - loss: 0.1560 - accuracy: 0.9392 - val_loss: 0.3935 - val_accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "n_steps = train_labels.shape[0] // BATCH_SIZE\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.359914</td>\n",
       "      <td>0.842623</td>\n",
       "      <td>0.302517</td>\n",
       "      <td>0.878112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289072</td>\n",
       "      <td>0.883197</td>\n",
       "      <td>0.295759</td>\n",
       "      <td>0.882781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263132</td>\n",
       "      <td>0.894148</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.885370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.240778</td>\n",
       "      <td>0.903538</td>\n",
       "      <td>0.305684</td>\n",
       "      <td>0.884564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218949</td>\n",
       "      <td>0.912840</td>\n",
       "      <td>0.320583</td>\n",
       "      <td>0.882781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.197384</td>\n",
       "      <td>0.921941</td>\n",
       "      <td>0.345204</td>\n",
       "      <td>0.878703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.176445</td>\n",
       "      <td>0.930593</td>\n",
       "      <td>0.372406</td>\n",
       "      <td>0.880611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.156003</td>\n",
       "      <td>0.939221</td>\n",
       "      <td>0.393461</td>\n",
       "      <td>0.878612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.359914  0.842623  0.302517      0.878112\n",
       "1  0.289072  0.883197  0.295759      0.882781\n",
       "2  0.263132  0.894148  0.293478      0.885370\n",
       "3  0.240778  0.903538  0.305684      0.884564\n",
       "4  0.218949  0.912840  0.320583      0.882781\n",
       "5  0.197384  0.921941  0.345204      0.878703\n",
       "6  0.176445  0.930593  0.372406      0.880611\n",
       "7  0.156003  0.939221  0.393461      0.878612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(train_history.history)\n",
    "hist_df.to_csv('train_history.csv')\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = load_model(max_len=MAX_LEN, architecture='xlm-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 69s 100ms/step\n",
      "AP: 0.9170765379994744\n",
      "ROC AUC: 0.9382573931497918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.88     44307\n",
      "           1       0.85      0.91      0.88     43734\n",
      "\n",
      "    accuracy                           0.88     88041\n",
      "   macro avg       0.88      0.88      0.88     88041\n",
      "weighted avg       0.88      0.88      0.88     88041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_score = model.predict(test_dataset, verbose=1).squeeze()\n",
    "y_pred = y_score.round().astype(int)\n",
    "print(\"AP:\", average_precision_score(test_labels, y_score))\n",
    "print(\"ROC AUC:\", roc_auc_score(test_labels, y_score))\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e0af10780884b6682b7696d797bf7b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f85ae5e3d4f34c07bee3395dfa53155b",
       "max": 910749124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f02629d694254e8c8b2559d76f2955d2",
       "value": 910749124.0
      }
     },
     "1020e2bf1a2a4aa3ab2cd36c9bc43746": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8a1e24489dd944c99b3a02d31945da66",
       "max": 618.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d50e376caa4e4a868322efa44e13b652",
       "value": 618.0
      }
     },
     "1575a453e3404ed4b347b9695bc420a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a9dc3621a2f4a259794a24f1faab86b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3cd53560c82b479aa3a05eeaf8be9f19": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5852799a1c604f459930d63b370e817c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0e0af10780884b6682b7696d797bf7b0",
        "IPY_MODEL_73c57e6ee3da40f2b238641cb8126e56"
       ],
       "layout": "IPY_MODEL_a10390669a444dcf8c90adcec2991f0c"
      }
     },
     "5a3b0901795c49a69c33a5302cea49b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b43e21f09134143aa92728a2a08d338": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1020e2bf1a2a4aa3ab2cd36c9bc43746",
        "IPY_MODEL_86a45af3bb6045e1811c78dc8a173082"
       ],
       "layout": "IPY_MODEL_b68284e37b5c49ac85f05da998f9dc5a"
      }
     },
     "73c57e6ee3da40f2b238641cb8126e56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a3b0901795c49a69c33a5302cea49b8",
       "placeholder": "​",
       "style": "IPY_MODEL_1575a453e3404ed4b347b9695bc420a1",
       "value": " 911M/911M [00:28&lt;00:00, 31.6MB/s]"
      }
     },
     "86a45af3bb6045e1811c78dc8a173082": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3cd53560c82b479aa3a05eeaf8be9f19",
       "placeholder": "​",
       "style": "IPY_MODEL_1a9dc3621a2f4a259794a24f1faab86b",
       "value": " 618/618 [00:00&lt;00:00, 686B/s]"
      }
     },
     "8a1e24489dd944c99b3a02d31945da66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a10390669a444dcf8c90adcec2991f0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b68284e37b5c49ac85f05da998f9dc5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d50e376caa4e4a868322efa44e13b652": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f02629d694254e8c8b2559d76f2955d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f85ae5e3d4f34c07bee3395dfa53155b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
